<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Job Prediction & Visual</title>
    <link rel="stylesheet" href="style.css">
    <script src="https://d3js.org/d3.v6.min.js"></script>
</head>
<body>
    <header>
        <div class="headerimg"><a href="index.html"><img src="Images/redlogo.webp" alt="logo"></a></div>
        <div class="headertext">
            <p><a href="#context" class="header-button">Context</a></p>
            <p><a href="#process1" class="header-button">Preprocessing</a></p>
            <p><a href="#process2" class="header-button">Machine Learning</a></p>
            <p><a href="#results" class="header-button">Results</a></p>
            <p><a href="#summary" class="header-button">Summary</a></p>
        </div>
    </header>


        <section class="bigsection">
            <h1>Data Visualization & Machine Learning Analysis<br>Fake Job Prediction</h1>
        </section>

    <div class="container">
        <section class="context" id="context">
            <h2>Context</h2>
            <p>
                The dataset used in this project is the "Real or Fake JobPosting Prediction" dataset made by Shivam Bansal, link <a href="https://www.kaggle.com/datasets/shivamb/real-or-fake-fake-jobposting-prediction">here</a>. This dataset contains information about job postings, which has 18K jobs, and 866 of them are fake. The purpose of this project is to analyze and visualize this dataset to gain insights into the characteristics of real and fake job postings, as well as to build machine learning models for job posting classification.
            </p>
            <p>
                The dataset includes various features such as job descriptions, company profiles, location, salary information, and more. It provides an opportunity to explore the patterns and trends in job postings and develop predictive models to identify fake job listings, which can be valuable for job seekers and recruiters.
            </p>
            <p>
                This data visualization example showcases various visualizations and analysis techniques applied to the dataset to better understand the information it contains and to assist in the development of machine learning models for fake job prediction.
            </p>
            <p>
                Explore the visualizations and analysis to gain insights into the world of job postings and learn how data science and machine learning can help in distinguishing between real and fake job opportunities.
            </p>
        </section>

        <section class="process" id="process1">
            <h2>Data Preprocessing for Machine Learning Classification</h2>
            
            <div class="step">
                <h3>Step 1: Loading the Dataset</h3>
                <ul>
                    <li>I started by loading the dataset, which is typically stored in a file (e.g., a CSV file). I used the dataset named "fake_job_postings.csv" from the Kaggle website.</li>
                </ul>
            </div>
        
            <div class="step">
                <h3>Step 2: Handling Missing Values</h3>
                <ul>
                    <li>Missing data can be problematic for machine learning models. I first check the dataset for missing values in each column.</li>
                    <li>If a numerical feature (e.g., salary range) has missing values, I fill them with the median value of that feature.</li>
                    <li>If a categorical feature (e.g., job description) has missing values, I replace them with 'Unknown' to ensure all data is accounted for.</li>
                </ul>
            </div>
        
            <div class="step">
                <h3>Step 3: Encoding Categorical Variables</h3>
                <ul>
                    <li>Machine learning models require numeric input, so I convert categorical variables (e.g., job location, employment type) into a numerical format using a technique called label-encoding for high cardinality features and one-hot encoding to other categorical columns. This allows the model to understand and work with these categorical features.</li>
                </ul>
            </div>
        
            <div class="step">
                <h3>Step 4: Splitting the Dataset</h3>
                <ul>
                    <li>I split the dataset into two parts: the "features" and the "target variable." The features contain the information used to make predictions, while the target variable is what I want the model to predict. For example, the target variable is "fraudulent".</li>
                </ul>
            </div>
        
            <div class="step">
                <h3>Step 5: Saving the Preprocessed Data</h3>
                <ul>
                    <li>Finally, I save the preprocessed data to as a new .csv file, "encoded_job_postings.csv," so that I can easily use it for training and testing machine learning models.</li>
                </ul>
            </div>
        </section>

        <div class="figure1">
            <img src="Images/Figure_1.png" alt="figure1">
            <p style="font-size: 14px; margin-top: 0;">Figure 1: Graph depicting an imbalance between real and fake jobs.</p>
        </div>

        <section class="process" id="process2">
            <h2>Machine Learning using the XGBoost Classifier</h2>
            
            <div class="step">
                <h3>Step 1: Data Preparation</h3>
                <p>The analysis began by loading a dataset containing information about job postings from a file named 'categorized_job_postings.csv.'</p>
            </div>

            <div class="step">
                <h3>Step 2: Data Splitting</h3>
                <p>The dataset was divided into two parts (70-30 split): one used to teach the computer model, and the other to test the model's predictions. This division helps assess how well the model performs.</p>
            </div>

            <div class="step">
                <h3>Step 3: Handling Class Imbalance</h3>
                <p>Special attention was given to the issue of class imbalance, where there were significantly more "non-fraudulent" job postings than "fraudulent" ones. Techniques were applied to balance the influence of both types during model training.</p>
            </div>

            <div class="step">
                <h3>Step 4: Building the Model</h3>
                <p>A machine learning model called the XGBoost Classifier was created. This model is capable of learning patterns in data and making predictions based on what it learns.</p>
            </div>

            <div class="step">
                <h3>Step 5: Model Training</h3>
                <p>The XGBoost model was trained using the data meant for teaching. During this process, the model learned to recognize patterns that distinguish "fraudulent" from "non-fraudulent" job postings.</p>
            </div>

            <div class="step">
                <h3>Step 6: Making Predictions</h3>
                <p>After being trained, the model was put to use by making predictions on another part of the data. These predictions indicated whether each job posting should be categorized as "fraudulent" or "non-fraudulent."</p>
            </div>

            <div class="step">
                <h3>Step 7: Assessing Model Performance</h3>
                <p>To understand how well the model performed, various measurements were calculated:</p>
                <ul>
                    <li>Accuracy Score: This metric gauges the overall correctness of the model's predictions.</li>
                    <li>Confusion Matrix: This is a table that shows the number of correct and incorrect predictions, offering insights into the model's performance.</li>
                    <li>Classification Report: Detailed metrics were generated to describe how well the model performed for each category.</li>
                </ul>
            </div>

            <div class="step">
                <h3>Step 8: Visualizing Model Performance</h3>
                <p>For better visualization and understanding, a heatmap representation of the confusion matrix was created. This heatmap visually displayed the model's predictions and errors, aiding in the assessment of how effectively it identified "fraudulent" job postings.</p>
            </div>
        </section>

        <section class="results" id="results">
            <h2>Results</h2>
            <div class="figure1">
                <div class="image-container">
                    <img src="Images/Figure_2.png" alt="figure2">
                    <img src="Images/Figure_3.png" alt="figure3">
                </div>
                <p style="font-size: 14px; margin-top: 0;">Figure 2: Confusion matrix depicting false and true predictions.</p>
                <p style="font-size: 14px; margin-top: 0;">Figure 3: ROC (Receiver Operating Characteristic), assesses the model's ability to distinguish between two job states (real vs fake)</p>
            </div>
            
            <div class="figure1">
                <img src="Images/Figure_4.png" alt="figure4">
                <p style="font-size: 14px; margin-top: 0;">Figure 4: Feature importance analysis showing which features were most important.</p>
            </div>

            <div class="resulttext">
                <h3>Classification Report & Accuracy</h3>
    
                <p>In reference to table 1, the classification report provides insights into how well the model performed in distinguishing between real and fake job postings. It presents several important metrics. The overall accuracy was <b>99%!</b></p>
            
                <h4>Precision (Accuracy of Positive Predictions):</h4>
                <p>For "real" job postings, the model achieved a precision of 99%. This means that when the model predicted a job posting as "real," it was correct 99% of the time.</p>
                <p>For "fake" job postings, the precision was 88%, indicating that 88% of the predicted "fake" postings were indeed fake.</p>
            
                <h4>Recall (Sensitivity or True Positive Rate):</h4>
                <p>The model's recall for "real" job postings was 99%, implying that it correctly identified 99% of the actual "real" job postings.</p>
                <p>For "fake" job postings, the recall was 83%, indicating that the model captured 83% of the actual "fake" job postings.</p>
            
                <h4>F1-Score (Balance Between Precision and Recall):</h4>
                <p>The F1-score combines precision and recall into a single metric, providing a balanced view of the model's performance.</p>
                <p>For "real" job postings, the F1-score was 0.99, reflecting a high balance between accuracy and completeness.</p>
                <p>For "fake" job postings, the F1-score was 0.86, indicating a reasonably good balance between precision and recall.</p>
            
                <h4>Accuracy (Overall Correctness):</h4>
                <p>The model achieved an accuracy of 99%, meaning that it correctly classified job postings as "real" or "fake" 99% of the time across the entire dataset.</p>
            
                <h4>Macro Average and Weighted Average:</h4>
                <p>The macro average provides an overall assessment of the model's performance by averaging the precision, recall, and F1-score across both "real" and "fake" categories.</p>
                <p>The weighted average considers the imbalanced dataset, giving more weight to the larger class ("real" job postings).</p>
            </div>

            <div class="table">
            <table class="classification-table">
                <caption>Table 1: Classification Report Table</caption>
                <thead>
                    <tr>
                        <th></th>
                        <th>Precision</th>
                        <th>Recall</th>
                        <th>F1-Score</th>
                        <th>Support</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <th>Real</th>
                        <td>0.99</td>
                        <td>0.99</td>
                        <td>0.99</td>
                        <td>5093</td>
                    </tr>
                    <tr>
                        <th>Fake</th>
                        <td>0.88</td>
                        <td>0.83</td>
                        <td>0.86</td>
                        <td>271</td>
                    </tr>
                    <tr class="accuracy-row">
                        <th>Accuracy</th>
                        <td colspan="4">0.99</td>
                    </tr>
                    <tr class="avg-row">
                        <th>Macro Avg</th>
                        <td>0.94</td>
                        <td>0.91</td>
                        <td>0.92</td>
                        <td>5364</td>
                    </tr>
                    <tr class="avg-row">
                        <th>Weighted Avg</th>
                        <td>0.99</td>
                        <td>0.99</td>
                        <td>0.99</td>
                        <td>5364</td>
                    </tr>
                </tbody>
            </table>
            </div>
        </section>

        <section class="summary" id="summary">
            <h1>Summary & Implications</h1>
            <p>The classification report reveals that the model effectively distinguishes between real and fake job postings, with high precision and recall rates. The F1-score indicates a good balance between accuracy and completeness, resulting in an impressive 99% accuracy overall.</p>
            <p>The model's strong performance implies its suitability for automated job posting verification, reducing the risk of fraudulent job listings and enhancing the efficiency of job platforms.</p>
        </section>

        
    </div>

    <footer>
        <p>Created by Michael Avila Salas</p>
        <p>Portfolio: <a href="https://michaelavilasalas.com">michaelavilasalas.com</a></p>
    </footer>
    
    <script src="script.js"></script>
</body>
</html>